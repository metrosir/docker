input {
  tcp {
    port => 10514
    mode => "server"
    ssl_enable => false
  }
}
filter {
  # 统一解析logspout日志
  dissect {
     mapping => {
       "message" => "%{?prefix} %{log_time} %{} %{service_name}.%{container_no}.%{?container_id} %{?pid} - - %{log_content}"
     }
  }
  date {
    match => ["log_time", "ISO8601"]
  }
  # 判断日志类型
  if [service_name] =~ /^.+php$/ {
    mutate {
      add_field => ["log_type", "app"]
    }
  } else if [service_name] =~ /^.+nginx$/ {
    mutate {
      add_field => ["log_type", "nginx"]
    }
  } else if [service_name] =~ /^.+java$/ {
    mutate {
      add_field => ["log_type", "java"]
    }
  } else {
    mutate {
      add_field => ["log_type", "other"]
    }
  }
  # 解析json 格式日志
  if [log_type] in ["app", "nginx"]{
    json {
      source => "log_content"
    }
  }
  # 获取落地路径
  if [log_type] == "app" {
    # 非json格式的日志 则为php日志
    if "_jsonparsefailure" in [tags] {
      mutate {
        replace   => ["log_type", "php"]
        add_field => ["log_path", "%{service_name}/%{+YYYYMM}/%{+YYYYMMdd}.log"]
      }
    }
  } else if [log_type] == "nginx" {
    # 非json格式的日志 为nginx error日志
    if "_jsonparsefailure" in [tags] {
      mutate {
        add_field => ["app", "error"]
        add_field => ["level", "error"]
        add_field => ["log_path", "error/%{+YYYYMM}/error.%{+YYYYMMdd}.log"]
      }
    }else{
      mutate {
        add_field => ["level", "info"]
        add_field => ["log_path", "%{app}/%{+YYYYMM}/access.%{+YYYYMMdd}.log"]
      }
    }
  } else if [log_type] == "java" {
    dissect {
     mapping => {
       "log_content" => "%{?date} %{?time} %{?timezone} %{level} [%{thread}] %{class}#%{method} - %{log_info}"
     }
  	}
  	mutate {
        replace   => ["app", "%{service_name}"]
        add_field => ["log_path", "%{service_name}/%{+YYYYMM}/%{+YYYYMMdd}.log"]
    }
  } else if [log_type] == "other" {
    mutate {
      add_field => ["log_path", "%{service_name}/%{+YYYYMM}/%{+YYYYMMdd}.log"]
    }
  }
  # 去掉不必要的数据项
  mutate {
    remove_field => ["message", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]
  }
}
output {
  file {
    path => "/mnt/logs/%{log_type}/%{log_path}"
    gzip => false #按gzip方式压缩
    flush_interval => 2  #指定刷入间隔(秒数)，0代表实时写入 默认2s
    codec => line {
      format => "%{log_content}"
    }
  }
  if [log_type] in ["app", "nginx", "java"]{
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "logstash-%{log_type}-%{app}-%{+YYYYMM}"
      document_type => "%{level}"
      flush_size => 1000 #批量上送数据最大条数 不会超过pipeline.batch.size 默认500
      idle_flush_time => 1 #批量上送数据间隔 默认1s
    }
  }
}